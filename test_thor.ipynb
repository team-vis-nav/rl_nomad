{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940149bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tuandang/miniconda3/envs/nomad_train/lib/python3.8/site-packages/ai2thor/controller.py:1416: UserWarning: start method depreciated. The server started when the Controller was initialized.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Environment setup\u001b[39;00m\n\u001b[1;32m     10\u001b[0m controller \u001b[38;5;241m=\u001b[39m Controller()\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcontroller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m controller\u001b[38;5;241m.\u001b[39mreset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFloorPlan1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m controller\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitialize\u001b[39m\u001b[38;5;124m'\u001b[39m, gridSize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nomad_train/lib/python3.8/site-packages/ai2thor/controller.py:1428\u001b[0m, in \u001b[0;36mController.start\u001b[0;34m(self, port, start_unity, width, height, x_display, host, player_screen_width, player_screen_height)\u001b[0m\n\u001b[1;32m   1424\u001b[0m env \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1426\u001b[0m image_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_unity:\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build\u001b[38;5;241m.\u001b[39mlock_sh()\n",
      "File \u001b[0;32m~/miniconda3/envs/nomad_train/lib/python3.8/site-packages/ai2thor/fifo_server.py:254\u001b[0m, in \u001b[0;36mFifoServer.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 254\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkfifo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver_pipe_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkfifo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient_pipe_path)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstarted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from ai2thor.controller import Controller\n",
    "from torchvision import transforms\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Environment setup\n",
    "controller = Controller()\n",
    "controller.start()\n",
    "controller.reset('FloorPlan1')\n",
    "controller.step(action='Initialize', gridSize=0.25)\n",
    "\n",
    "# Preprocess camera image\n",
    "def preprocess(frame):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(frame).unsqueeze(0)\n",
    "\n",
    "# Policy network\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(32 * 6 * 6, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.actor = nn.Linear(256, 4)   # 4 actions\n",
    "        self.critic = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return self.actor(x), self.critic(x) # pi(at|st)=argmax Q(St,At), V(st)\n",
    "\n",
    "# Action mapping\n",
    "ACTIONS = ['MoveAhead', 'MoveBack', 'RotateLeft', 'RotateRight']\n",
    "\n",
    "# Hyperparameters\n",
    "policy = PolicyNet()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)\n",
    "gamma = 0.99\n",
    "eps_clip = 0.2\n",
    "\n",
    "# Training loop\n",
    "for episode in range(1000):\n",
    "    controller.reset('FloorPlan1')\n",
    "    controller.step(action='Initialize', gridSize=0.25)\n",
    "    event = controller.step(action='LookDown')\n",
    "    image = preprocess(event.frame)\n",
    "\n",
    "    log_probs, rewards, values, actions = [], [], [], []\n",
    "    done = False\n",
    "\n",
    "    for t in range(100):\n",
    "        logits, value = policy(image) # on-policy\n",
    "        dist = Categorical(logits=logits)\n",
    "        action = dist.sample()\n",
    "\n",
    "        act_name = ACTIONS[action.item()]\n",
    "        event = controller.step(action=act_name)\n",
    "\n",
    "        reward = 1.0 if 'objectId' in event.metadata['lastActionSuccess'] else -0.01\n",
    "        done = not event.metadata['lastActionSuccess']\n",
    "        \n",
    "        log_probs.append(dist.log_prob(action))\n",
    "        values.append(value.squeeze())\n",
    "        rewards.append(torch.tensor(reward, dtype=torch.float))\n",
    "        actions.append(action)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        image = preprocess(event.frame)\n",
    "\n",
    "    # Compute returns and advantages\n",
    "    returns, advs = [], []\n",
    "    G = 0 # return\n",
    "    for r in reversed(rewards):\n",
    "        G = r + gamma * G # REturns: Q-Learning, SARSA, On-policy / Off-policy\n",
    "        returns.insert(0, G)\n",
    "    returns = torch.tensor(returns)\n",
    "    values = torch.stack(values)\n",
    "    advantages = returns - values.detach() # G - V(St)\n",
    "\n",
    "    # PPO loss\n",
    "    log_probs = torch.stack(log_probs)\n",
    "    old_log_probs = log_probs.detach()\n",
    "    for _ in range(4):  # K epochs\n",
    "        logits, value = policy(image)\n",
    "        dist = Categorical(logits=logits)\n",
    "        new_log_probs = dist.log_prob(torch.stack(actions))\n",
    "        ratio = torch.exp(new_log_probs - old_log_probs)\n",
    "\n",
    "        surr1 = ratio * advantages\n",
    "        surr2 = torch.clamp(ratio, 1 - eps_clip, 1 + eps_clip) * advantages\n",
    "        policy_loss = -torch.min(surr1, surr2).mean()\n",
    "        value_loss = (returns - value.squeeze()).pow(2).mean()\n",
    "\n",
    "        loss = policy_loss + 0.5 * value_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Episode {episode}: Total Reward = {sum(rewards).item():.2f}\")\n",
    "\n",
    "controller.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nomad_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
