Loaded splits from /home/tuandang/tuandang/quanganh/visualnav-transformer/train/Unified/config/splits/combined_splits.yaml
Dataset: combined
Train scenes: 156
Val scenes: 27
Test scenes: 26
Starting unified training with curriculum learning for 1000000 timesteps...
Dataset: combined
Stage: 1
Using single environment instance to avoid Unity conflicts
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
torch obs:  torch.Size([1, 3, 224, 224])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
Traceback (most recent call last):
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/PIL/ImageFile.py", line 547, in _save
    fh = fp.fileno()
AttributeError: '_idat' object has no attribute 'fileno'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "Train.py", line 729, in <module>
    main()
  File "Train.py", line 708, in main
    results = trainer.train_val_test(config[f'stage{args.stage}_timesteps'])
  File "Train.py", line 413, in train_val_test
    rollout_stats = self.collect_rollouts(self.config['rollout_steps'])
  File "Train.py", line 218, in collect_rollouts
    save_image(next_torch_obs['rgb'].squeeze(), f"output_image{step}.png")
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/torchvision/utils.py", line 151, in save_image
    im.save(fp, format=format)
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/PIL/Image.py", line 2568, in save
    save_handler(self, fp, filename)
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/PIL/PngImagePlugin.py", line 1431, in _save
    ImageFile._save(im, _idat(fp, chunk), [("zip", (0, 0) + im.size, 0, rawmode)])
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/PIL/ImageFile.py", line 551, in _save
    _encode_tile(im, fp, tile, bufsize, None, exc)
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/PIL/ImageFile.py", line 570, in _encode_tile
    errcode, data = encoder.encode(bufsize)[1:]
KeyboardInterrupt