Loaded splits from /home/tuandang/tuandang/quanganh/visualnav-transformer/train/Unified/config/splits/combined_splits.yaml
Dataset: combined
Train scenes: 156
Val scenes: 27
Test scenes: 26
Starting unified training with curriculum learning for 1000000 timesteps...
Dataset: combined
Stage: 1
Using single environment instance to avoid Unity conflicts
torch obs:  {'rgb': tensor([[[[0.4000, 0.4000, 0.3922,  ..., 0.4118, 0.4118, 0.4118],
          [0.3922, 0.3882, 0.3922,  ..., 0.4078, 0.4078, 0.4118],
          [0.3922, 0.3922, 0.3882,  ..., 0.4039, 0.4118, 0.4118],
          ...,
          [0.4078, 0.4078, 0.4078,  ..., 0.4627, 0.4588, 0.4627],
          [0.4078, 0.4078, 0.4118,  ..., 0.4667, 0.4627, 0.4667],
          [0.4078, 0.4039, 0.4000,  ..., 0.4667, 0.4667, 0.4667]],
         [[0.3647, 0.3608, 0.3608,  ..., 0.3294, 0.3294, 0.3294],
          [0.3608, 0.3608, 0.3608,  ..., 0.3294, 0.3255, 0.3294],
          [0.3608, 0.3608, 0.3569,  ..., 0.3255, 0.3294, 0.3294],
          ...,
          [0.3529, 0.3490, 0.3490,  ..., 0.3765, 0.3765, 0.3765],
          [0.3529, 0.3529, 0.3529,  ..., 0.3804, 0.3765, 0.3804],
          [0.3529, 0.3529, 0.3451,  ..., 0.3804, 0.3804, 0.3765]],
         [[0.2980, 0.2941, 0.2902,  ..., 0.1765, 0.1765, 0.1804],
          [0.2902, 0.2902, 0.2902,  ..., 0.1765, 0.1765, 0.1765],
          [0.2902, 0.2902, 0.2902,  ..., 0.1765, 0.1765, 0.1765],
          ...,
          [0.2588, 0.2549, 0.2588,  ..., 0.2000, 0.2000, 0.2000],
          [0.2549, 0.2588, 0.2588,  ..., 0.2000, 0.2000, 0.2000],
          [0.2588, 0.2588, 0.2510,  ..., 0.2000, 0.2000, 0.2000]]]],
       device='cuda:0'), 'goal_rgb': tensor([[[[0.3882, 0.3882, 0.3922,  ..., 0.3529, 0.3529, 0.5020],
          [0.3804, 0.3882, 0.3882,  ..., 0.3569, 0.5098, 0.4784],
          [0.3804, 0.3882, 0.3765,  ..., 0.5059, 0.4745, 0.4863],
          ...,
          [0.2980, 0.2471, 0.3608,  ..., 0.5176, 0.5216, 0.5255],
          [0.3059, 0.2588, 0.3098,  ..., 0.5176, 0.5176, 0.5255],
          [0.3490, 0.2980, 0.2392,  ..., 0.5176, 0.5176, 0.5255]],
         [[0.3569, 0.3569, 0.3569,  ..., 0.3294, 0.3294, 0.4941],
          [0.3529, 0.3529, 0.3529,  ..., 0.3333, 0.5059, 0.4706],
          [0.3529, 0.3529, 0.3490,  ..., 0.5020, 0.4706, 0.4667],
          ...,
          [0.2039, 0.1608, 0.3059,  ..., 0.4157, 0.4196, 0.4196],
          [0.2118, 0.1647, 0.2275,  ..., 0.4157, 0.4196, 0.4196],
          [0.2510, 0.2039, 0.1647,  ..., 0.4157, 0.4196, 0.4196]],
         [[0.2824, 0.2863, 0.2902,  ..., 0.2745, 0.2745, 0.4745],
          [0.2824, 0.2824, 0.2863,  ..., 0.2784, 0.4863, 0.4510],
          [0.2824, 0.2824, 0.2784,  ..., 0.4824, 0.4510, 0.4314],
          ...,
          [0.1255, 0.0941, 0.2196,  ..., 0.2157, 0.2157, 0.2157],
          [0.1451, 0.1020, 0.1373,  ..., 0.2157, 0.2157, 0.2196],
          [0.1725, 0.1216, 0.1020,  ..., 0.2157, 0.2157, 0.2196]]]],
       device='cuda:0'), 'context': tensor([[[[0.4000, 0.4000, 0.3922,  ..., 0.4118, 0.4118, 0.4118],
          [0.3922, 0.3882, 0.3922,  ..., 0.4078, 0.4078, 0.4118],
          [0.3922, 0.3922, 0.3882,  ..., 0.4039, 0.4118, 0.4118],
          ...,
          [0.4078, 0.4078, 0.4078,  ..., 0.4627, 0.4588, 0.4627],
          [0.4078, 0.4078, 0.4118,  ..., 0.4667, 0.4627, 0.4667],
          [0.4078, 0.4039, 0.4000,  ..., 0.4667, 0.4667, 0.4667]],
         [[0.3647, 0.3608, 0.3608,  ..., 0.3294, 0.3294, 0.3294],
          [0.3608, 0.3608, 0.3608,  ..., 0.3294, 0.3255, 0.3294],
          [0.3608, 0.3608, 0.3569,  ..., 0.3255, 0.3294, 0.3294],
          ...,
          [0.3529, 0.3490, 0.3490,  ..., 0.3765, 0.3765, 0.3765],
          [0.3529, 0.3529, 0.3529,  ..., 0.3804, 0.3765, 0.3804],
          [0.3529, 0.3529, 0.3451,  ..., 0.3804, 0.3804, 0.3765]],
         [[0.2980, 0.2941, 0.2902,  ..., 0.1765, 0.1765, 0.1804],
          [0.2902, 0.2902, 0.2902,  ..., 0.1765, 0.1765, 0.1765],
          [0.2902, 0.2902, 0.2902,  ..., 0.1765, 0.1765, 0.1765],
          ...,
          [0.2588, 0.2549, 0.2588,  ..., 0.2000, 0.2000, 0.2000],
          [0.2549, 0.2588, 0.2588,  ..., 0.2000, 0.2000, 0.2000],
          [0.2588, 0.2588, 0.2510,  ..., 0.2000, 0.2000, 0.2000]],
         ...,
         [[0.4000, 0.4000, 0.3922,  ..., 0.4118, 0.4118, 0.4118],
          [0.3922, 0.3882, 0.3922,  ..., 0.4078, 0.4078, 0.4118],
          [0.3922, 0.3922, 0.3882,  ..., 0.4039, 0.4118, 0.4118],
          ...,
          [0.4078, 0.4078, 0.4078,  ..., 0.4627, 0.4588, 0.4627],
          [0.4078, 0.4078, 0.4118,  ..., 0.4667, 0.4627, 0.4667],
          [0.4078, 0.4039, 0.4000,  ..., 0.4667, 0.4667, 0.4667]],
         [[0.3647, 0.3608, 0.3608,  ..., 0.3294, 0.3294, 0.3294],
          [0.3608, 0.3608, 0.3608,  ..., 0.3294, 0.3255, 0.3294],
          [0.3608, 0.3608, 0.3569,  ..., 0.3255, 0.3294, 0.3294],
          ...,
          [0.3529, 0.3490, 0.3490,  ..., 0.3765, 0.3765, 0.3765],
          [0.3529, 0.3529, 0.3529,  ..., 0.3804, 0.3765, 0.3804],
          [0.3529, 0.3529, 0.3451,  ..., 0.3804, 0.3804, 0.3765]],
         [[0.2980, 0.2941, 0.2902,  ..., 0.1765, 0.1765, 0.1804],
          [0.2902, 0.2902, 0.2902,  ..., 0.1765, 0.1765, 0.1765],
          [0.2902, 0.2902, 0.2902,  ..., 0.1765, 0.1765, 0.1765],
          ...,
          [0.2588, 0.2549, 0.2588,  ..., 0.2000, 0.2000, 0.2000],
          [0.2549, 0.2588, 0.2588,  ..., 0.2000, 0.2000, 0.2000],
          [0.2588, 0.2588, 0.2510,  ..., 0.2000, 0.2000, 0.2000]]]],
       device='cuda:0'), 'goal_mask': tensor([[0.]], device='cuda:0'), 'goal_position': tensor([[-2.2500,  0.9010,  1.5000]], device='cuda:0')}
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
Traceback (most recent call last):
  File "Train.py", line 725, in <module>
    main()
  File "Train.py", line 704, in main
    results = trainer.train_val_test(config[f'stage{args.stage}_timesteps'])
  File "Train.py", line 409, in train_val_test
    rollout_stats = self.collect_rollouts(self.config['rollout_steps'])
  File "Train.py", line 195, in collect_rollouts
    outputs = self.model.forward(
  File "/home/tuandang/tuandang/quanganh/visualnav-transformer/train/TwoStage/nomad_model.py", line 117, in forward
    if torch.isnan(value).any() or torch.isinf(value).any():
KeyboardInterrupt