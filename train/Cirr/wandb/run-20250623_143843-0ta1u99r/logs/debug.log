2025-06-23 14:38:43,645 INFO    MainThread:892216 [wandb_setup.py:_flush():70] Current SDK version is 0.19.11
2025-06-23 14:38:43,645 INFO    MainThread:892216 [wandb_setup.py:_flush():70] Configure stats pid to 892216
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_setup.py:_flush():70] Loading settings from /home/tuandang/.config/wandb/settings
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_setup.py:_flush():70] Loading settings from /home/tuandang/tuandang/quanganh/visualnav-transformer/train/Cirr/wandb/settings
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_setup.py:_flush():70] Loading settings from environment variables
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_init.py:setup_run_log_directory():724] Logging user logs to /home/tuandang/tuandang/quanganh/visualnav-transformer/train/Cirr/wandb/run-20250623_143843-0ta1u99r/logs/debug.log
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to /home/tuandang/tuandang/quanganh/visualnav-transformer/train/Cirr/wandb/run-20250623_143843-0ta1u99r/logs/debug-internal.log
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_init.py:init():852] calling init triggers
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_init.py:init():857] wandb.init called with sweep_config: {}
config: {'dataset': 'combined', 'image_size': [224, 224], 'max_episode_steps': 500, 'success_distance': 1.0, 'context_size': 5, 'goal_prob': 0.5, 'eval_goal_prob': 1.0, 'encoding_size': 256, 'mha_num_attention_heads': 4, 'mha_num_attention_layers': 4, 'mha_ff_dim_factor': 4, 'hidden_dim': 512, 'lstm_hidden_size': 256, 'lstm_num_layers': 2, 'curriculum_window_size': 100, 'curriculum_success_threshold': 0.7, 'curriculum_min_episodes': 100, 'curriculum_update_freq': 10, 'training_stage': 1, 'stage1_timesteps': 1000000, 'stage2_timesteps': 2000000, 'learning_rate': 0.001, 'stage1_learning_rate': 0.001, 'stage2_learning_rate': 0.0001, 'success_reward': 100.0, 'distance_weight': 20.0, 'step_penalty': 0.005, 'collision_penalty': 1.0, 'exploration_bonus': 5.0, 'curiosity_weight': 0.1, 'rollout_steps': 512, 'buffer_size': 512, 'batch_size': 16, 'ppo_epochs': 4, 'gamma': 0.99, 'lam': 0.95, 'clip_ratio': 0.2, 'entropy_coef': 0.01, 'value_coef': 0.5, 'distance_coef': 0.1, 'auxiliary_coef': 0.1, 'max_grad_norm': 0.5, 'use_amp': True, 'device': 'cuda', 'eval_episodes': 20, 'val_freq': 100, 'eval_freq': 100, 'log_freq': 10, 'save_freq': 50, 'save_dir': './checkpoints/curriculum', 'use_wandb': True, 'wandb_project': 'nomad-rl-curriculum', 'run_name': 'curriculum_training', '_wandb': {}}
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_init.py:init():893] starting backend
2025-06-23 14:38:43,646 INFO    MainThread:892216 [wandb_init.py:init():897] sending inform_init request
2025-06-23 14:38:43,662 INFO    MainThread:892216 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-06-23 14:38:43,662 INFO    MainThread:892216 [wandb_init.py:init():907] backend started and connected
2025-06-23 14:38:43,664 INFO    MainThread:892216 [wandb_init.py:init():1005] updated telemetry
2025-06-23 14:38:43,674 INFO    MainThread:892216 [wandb_init.py:init():1029] communicating run to backend with 90.0 second timeout
2025-06-23 14:38:44,060 INFO    MainThread:892216 [wandb_init.py:init():1104] starting run threads in backend
2025-06-23 14:38:44,118 INFO    MainThread:892216 [wandb_run.py:_console_start():2573] atexit reg
2025-06-23 14:38:44,118 INFO    MainThread:892216 [wandb_run.py:_redirect():2421] redirect: wrap_raw
2025-06-23 14:38:44,118 INFO    MainThread:892216 [wandb_run.py:_redirect():2490] Wrapping output streams.
2025-06-23 14:38:44,118 INFO    MainThread:892216 [wandb_run.py:_redirect():2513] Redirects installed.
2025-06-23 14:38:44,119 INFO    MainThread:892216 [wandb_init.py:init():1150] run started, returning control to user process
2025-06-23 15:42:57,207 INFO    MsgRouterThr:892216 [mailbox.py:close():129] [no run ID] Closing mailbox, abandoning 1 handles.
