Loaded splits from /home/tuandang/tuandang/quanganh/visualnav-transformer/train/Unified/config/splits/combined_splits.yaml
Dataset: combined
Train scenes: 156
Val scenes: 27
Test scenes: 26
Starting unified training with curriculum learning for 1000000 timesteps...
Dataset: combined
Stage: 1
Using single environment instance to avoid Unity conflicts
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
input obs shape: torch.Size([1, 15, 224, 224])
input goal shape: torch.Size([1, 6, 224, 224])
shape after effnet: torch.Size([5, 1280, 7, 7])
shape after avgpooling: torch.Size([5, 1280, 1, 1])
shape after flatten: torch.Size([5, 1280])
Error in vision encoder: shape '[6, -1, 256]' is invalid for input of size 1280
obs_img shape: torch.Size([1, 15, 224, 224])
obsgoal_img shape: torch.Size([1, 6, 224, 224])
goal_mask shape: torch.Size([1, 1])
Traceback (most recent call last):
  File "Train.py", line 724, in <module>
    main()
  File "Train.py", line 703, in main
    results = trainer.train_val_test(config[f'stage{args.stage}_timesteps'])
  File "Train.py", line 408, in train_val_test
    rollout_stats = self.collect_rollouts(self.config['rollout_steps'])
  File "Train.py", line 261, in collect_rollouts
    obs = self.env.reset()
  File "/home/tuandang/tuandang/quanganh/visualnav-transformer/train/nomad_rl/environments/ai2thor_nomad_env.py", line 83, in reset
    self.controller.reset(scene=scene_name)
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/ai2thor/controller.py", line 589, in reset
    self.last_event = self.server.receive()
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/ai2thor/fifo_server.py", line 170, in receive
    metadata, files = self._recv_message()
  File "/home/tuandang/anaconda3/envs/nomad_train/lib/python3.8/site-packages/ai2thor/fifo_server.py", line 102, in _recv_message
    header = self.server_pipe.read(self.header_size) # message type + length
KeyboardInterrupt