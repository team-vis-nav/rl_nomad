{"approx_kl":0.011945507762720808,"policy_loss":-0.0010490665445104241,"goal_conditioned_reward":-113.81770906894546,"episode_reward_mean":-113.19292357985267,"_step":5,"_wandb":{"runtime":9892},"timesteps":122880,"distance_loss":7.292853153683245,"exploration_reward":-66.34199999999986,"_timestamp":1.748975872085351e+09,"clip_fraction":0.12109375,"episode_length_mean":481.48,"success_rate":0.5,"value_loss":37.98154891729355,"entropy":1.4672531787306071,"_runtime":9134.74540999}